<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    
    <title>Linear Support Vector Machines &#8212; Shark 3.0a documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mt_sphinx_deriv.css?v=6ec4729f" />
    <script src="../../../_static/documentation_options.js?v=db277b1a"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="icon" href="../../../_static/shark16.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Kernel Target Alignment" href="kta.html" />
    <link rel="prev" title="Linear Kernel Combinations (and a bit of MKL)" href="lkc-mkl.html" />
    <link rel="stylesheet" href="../../../_static/mt_sphinx_shark.css" type="text/css" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js?config=TeX-AMS_CHTML"></script>
    <script src="../../../index/../../../../mlstyle.js"></script>

  </head><body>

    <div id="shark_old">
        <div id="wrap">
            <div id="header">
                <div id="site-name"><a href="../../../index/../../../../index.html">Shark machine learning library</a></div>
                <ul id="nav">
                    <li  class="first" >
                        <a href="../../installation.html">Installation</a>
                    </li>
                    <li  class="active" >
                        <a href="../tutorials.html">Tutorials</a>
                    </li>
		    <li  class="first" >
                        <a href="../../benchmark.html">Benchmarks</a>
                    </li>
		    <li  class="first" >
                        <a href="../../../index/../../../../doxygen_pages/html/classes.html">Documentation</a>
                        <ul>
                            <li><a href="../../quickref/quickref.html">Quick references</a></li>
                            <li><a href="../../../index/../../../../doxygen_pages/html/classes.html">Class list</a></li>
                            <li class="last"><a href="../../../index/../../../../doxygen_pages/html/group__shark__globals.html">Global functions</a></li>
                        </ul>
                    </li>
                </ul>

            </div>
        </div>
    </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="linear-support-vector-machines">
<h1>Linear Support Vector Machines<a class="headerlink" href="#linear-support-vector-machines" title="Link to this heading">¶</a></h1>
<p>Support vector machines (SVMs) are traditionally viewed as a
kernel-based learning method. However, flexible non-linear models are
not always needed, and in particular for huge scale feature spaces
(e.g., in text mining and bioinformatics) linear models are sufficiently
rich. The decisive advantage of linear SVMs is that they can be trained
significantly faster than kernel-based models. Coordinate Descent (CD)
training of the dual problem is per iteration faster by a factor up to
the number of data points <a class="reference internal" href="#hclks-2008" id="id1"><span>[HCLKS-2008]</span></a>, which can make a big difference.
The algorithms implemented in Shark closely follow <a class="reference internal" href="#gu-2013" id="id2"><span>[GU-2013]</span></a>.</p>
<p>Shark provides various trainers for linear SVMs. These are mostly
analogous to the non-linear case. Therefore you may wish to read the
tutorial on SVMs first if you have not yet done so: <a class="reference internal" href="svm.html"><span class="doc">Support Vector Machines: First Steps</span></a></p>
<p>As usual we start with the necessary includes</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Data/Dataset.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/ObjectiveFunctions/Loss/ZeroOneLoss.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Algorithms/Trainers/CSvmTrainer.h&gt;</span>


<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Algorithms/Trainers/CSvmTrainer.h&gt;</span>
</pre></div>
</div>
<p>where the last line is one possible choice for multi-class problems,
see below.</p>
<p>For a linear SVM to be applicable the input components of the data need
to be vector valued. We consider one of the following, depending on
whether inputs are sparse or not:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">typedef</span><span class="w"> </span><span class="n">RealVector</span><span class="w"> </span><span class="n">VectorType</span><span class="p">;</span>
<span class="c1">// or:</span>
<span class="c1">// typedef CompressedRealVector VectorType;</span>
</pre></div>
</div>
<p>With this definition in place we instanciate a linear classifier model:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">LinearClassifier</span><span class="o">&lt;</span><span class="n">VectorType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">model</span><span class="p">;</span>
</pre></div>
</div>
<p>mapping inputs to <cite>unsigned int</cite> class labels. This is just a standard
<a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_linear_model.html">LinearModel</a>, whose outputs are converted to a class label
with an <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_classifier.html">Classifier</a>. So it computes one linear function per class
and predicts the class that got the highest score (a single value is
computed and thresholded at zero in case of only two classes).</p>
<section id="machine-training">
<h2>Machine Training<a class="headerlink" href="#machine-training" title="Link to this heading">¶</a></h2>
<p>Given a classification data set</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">LabeledData</span><span class="o">&lt;</span><span class="n">VectorType</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">training</span><span class="p">;</span>
</pre></div>
</div>
<p>and a regulariztion constant C &gt; 0 we can train a linear SVM.
Assuming binary labels the default is to use a C-SVM:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">LinearCSvmTrainer</span><span class="o">&lt;</span><span class="n">VectorType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">trainer</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>


<span class="n">trainer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="p">);</span>
</pre></div>
</div>
<p>A major difference to the non-linear case is that we do not need to
define a kernel (and thus there is no need to tune kernel parameters).
Of course we can make predictions and evaluate the model with a loss
function in the usual way:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">ZeroOneLoss</span><span class="o">&lt;</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">loss</span><span class="p">;</span>
<span class="n">Data</span><span class="o">&lt;</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">(</span><span class="n">training</span><span class="p">.</span><span class="n">inputs</span><span class="p">());</span>
<span class="kt">double</span><span class="w"> </span><span class="n">train_error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="p">.</span><span class="n">eval</span><span class="p">(</span><span class="n">training</span><span class="p">.</span><span class="n">labels</span><span class="p">(),</span><span class="w"> </span><span class="n">output</span><span class="p">);</span>
<span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;training error:</span><span class="se">\t</span><span class="s">&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w">  </span><span class="n">train_error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">endl</span><span class="p">;</span>
</pre></div>
</div>
<p>For SVMs the case of more than two classes is very different from the
binary classification setting. For this so-called multi-class case there
is a broad variety of methods available, varying mostly in the loss
employed for training. The one-versus-all (OVA) method is a strong
baseline:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">LinearCSvmTrainer</span><span class="o">&lt;</span><span class="n">VectorType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">trainer</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">epsilon</span><span class="p">);</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">setMcSvmType</span><span class="p">(</span><span class="n">McSvm</span><span class="o">::</span><span class="n">OVA</span><span class="p">);</span>
</pre></div>
</div>
<p>Other possibilities are the machines proposed by Weston and Watkins
(<cite>McSvm::WW</cite>), Crammer and Singer (<cite>McSvm::CS</cite>),
Lee, Lin and Wahba (<cite>McSvm::LLW</cite>), and many more
(<cite>McSvm::ReinforcedSvm</cite>, <cite>McSvm::MMR</cite>, <cite>McSvm::ADM</cite>,
<cite>McSvm::ATM</cite>, and <cite>McSvm::ATS</cite>).</p>
<p>Being left with this much choice is probably not helpful. In our
experience the best strategy for picking a machine is to try WW and CS
first, and LLW and ATS for high-dimensional feature spaces. OVA can be
useful at times, and MMR, ADM and ATM can usually be ignored. The
default choice by the Trainer is WW.</p>
<p>Currently Shark does not provide a specialized trainer for linear SVM
regression. Of course the non-linear <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_epsilon_svm_trainer.html">EpsilonSvmTrainer</a> can be
used with a <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_linear_kernel.html">LinearKernel</a> for this purpose.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="hclks-2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">HCLKS-2008</a><span class="fn-bracket">]</span></span>
<p>C. J. Hsieh, K. W. Chang, C. J. Lin, S. S. Keerthi, and S. Sundararajan.
A dual coordinate descent method for large-scale linear SVM.
In Proceedings of the 30th International Conference on Machine learning (ICML), 2008.</p>
</div>
<div class="citation" id="gu-2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">GU-2013</a><span class="fn-bracket">]</span></span>
<p>T. Glasmachers and Ü. Dogan.
Accelerated Coordinate Descent with Adaptive Coordinate Frequencies.
In Proceedings of the fifth Asian Conference on Machine Learning (ACML), 2013.</p>
</div>
</div>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
	<div class="mt_ltocwrapper">
		<ul>
<li><a class="reference internal" href="#">Linear Support Vector Machines</a><ul>
<li><a class="reference internal" href="#machine-training">Machine Training</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

	</div>
<div>
  <a class="topless" href="lkc-mkl.html" title="previous chapter">
	  <img class="navicon" src="../../../_static/icon_backward.png" alt="prev"/> Linear Kernel Combinations (and a bit of MKL)</a>
  <a class="topless" href="kta.html" title="next chapter">
	  <img class="navicon" src="../../../_static/icon_forward.png" alt="next"/> Kernel Target Alignment</a>
</div> 
<div id="searchbox" style="display: none">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" size="12" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      <input class="mtsubmitbutton" type="submit" value="Find" />
    </form>
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
<p class="mtshowsource">
  <a href="../../../_sources/rest_sources/tutorials/algorithms/linear-svm.rst.txt"
           rel="nofollow"><img class="sourceicon" src="../../../_static/icon_eject.png" alt="prev"/> Show page source</a>
</p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
        <div class="footerlogos">
            <a href="http://validator.w3.org/check/referer" title="Valid XHTML 1.0">
                <img class="footerlogos" src="../../../_static/xhtml_validation.png" alt="Valid XHTML 1.0" />
            </a>
            <a href="http://jigsaw.w3.org/css-validator/check/referer?profile=css3" title="Valid CSS3">
                <img class="footerlogos" src="../../../_static/css_validation.png" alt="Valid CSS3" />
            </a>
        </div>
            &copy; The Shark developer team.
           Created on 21/05/2024
           using <a href="http://sphinx.pocoo.org/">Sphinx</a> 7.3.7
    </div>
  </body>
</html>