<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    
    <title>Autoencoders &#8212; Shark 3.0a documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mt_sphinx_deriv.css?v=6ec4729f" />
    <script src="../../../_static/documentation_options.js?v=db277b1a"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntilConfig"></script>
    <link rel="icon" href="../../../_static/shark16.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Variational Autoencoders" href="variational_autoencoders.html" />
    <link rel="prev" title="Data Shapes and Deep Convolutional Architectures" href="DeepMNIST.html" />
    <link rel="stylesheet" href="../../../_static/mt_sphinx_shark.css" type="text/css" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js?config=TeX-AMS_CHTML"></script>
    <script src="../../../index/../../../../mlstyle.js"></script>

  </head><body>

    <div id="shark_old">
        <div id="wrap">
            <div id="header">
                <div id="site-name"><a href="/Shark/index.html">Shark machine learning library</a></div>
                <ul id="nav">
                    <li  class="first" >
                        <a href="../../installation.html">Installation</a>
                    </li>
                    <li  class="active" >
                        <a href="../tutorials.html">Tutorials</a>
                    </li>
		    <li  class="first" >
                        <a href="../../benchmark.html">Benchmarks</a>
                    </li>
		    <li  class="first" >
                        <a href="../../../index/../../../../doxygen_pages/html/classes.html">Documentation</a>
                        <ul>
                            <li><a href="../../quickref/quickref.html">Quick references</a></li>
                            <li><a href="../../../index/../../../../doxygen_pages/html/classes.html">Class list</a></li>
                            <li class="last"><a href="../../../index/../../../../doxygen_pages/html/group__shark__globals.html">Global functions</a></li>
                        </ul>
                    </li>
                </ul>

            </div>
        </div>
    </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="autoencoders">
<h1>Autoencoders<a class="headerlink" href="#autoencoders" title="Link to this heading">¶</a></h1>
<p>An autoencoder is a feed forward neural network which is trained to map
its input to itself via the representation formed by the hidden units. The optimisation
problem for input data <span class="math notranslate nohighlight">\(\vec{x}_1,\dots,\vec{x}_N\)</span> is stated as:</p>
<div class="math notranslate nohighlight">
\[\min_{\theta} \frac 1 N \sum_{i=1}^N (\vec x_i - f_{\theta}(\vec x_i))^2 \enspace .\]</div>
<p>Of course, without any constraints this is a simple task as the model
will just try to learn the identity. It becomes a bit more challenging
when we restrict the size of the intermediate representation (i.e.,
the number of hidden units). An image with several hundred input
points can not be squeezed in a representation of a few hidden
neurons. Thus, it is assumed that this intermediate representation
learns something meaningful about the problem.  Of course, using this
simple technique without any additional regularization
only works if the number of hidden neurons is smaller than
the number of dimensions of the image.</p>
<p>As a dataset for this tutorial, we use a subset of the MNIST dataset which needs to
be unzipped first. It can be found in <code class="docutils literal notranslate"><span class="pre">examples/Supervised/data/mnist_subset.zip</span></code>.
The full example program can be found in  <a class="reference external" href="../../../../../../doxygen_pages/html/_auto_encoder_tutorial_8cpp.html">AutoEncoderTutorial.cpp</a>.</p>
<p>The following includes are needed for this tutorial:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Data/Pgm.h&gt;</span><span class="c1"> //for exporting the learned filters</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Data/SparseData.h&gt;</span><span class="c1">//for reading in the images as sparseData/Libsvm format</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Models/LinearModel.h&gt;</span><span class="c1">//single dense layer</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Models/ConcatenatedModel.h&gt;</span><span class="c1">//for stacking layers</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/ObjectiveFunctions/ErrorFunction.h&gt;</span><span class="c1"> //the error function for minibatch training</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Algorithms/GradientDescent/Adam.h&gt;</span><span class="c1">// The Adam optimization algorithm</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/ObjectiveFunctions/Loss/SquaredLoss.h&gt;</span><span class="c1"> // squared loss used for regression</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/ObjectiveFunctions/Regularizer.h&gt;</span><span class="c1"> //L2 regulariziation</span>
</pre></div>
</div>
<section id="training-autoencoders">
<h2>Training autoencoders<a class="headerlink" href="#training-autoencoders" title="Link to this heading">¶</a></h2>
<p>Training an autoencoder is straight forward in shark. We just setup two neural networks,
one for encoding and one for decoding. Those are then concatenated to form one autoencoder
network:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">//We use a dense lienar model with rectifier activations</span>
<span class="k">typedef</span><span class="w"> </span><span class="n">LinearModel</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="p">,</span><span class="w"> </span><span class="n">RectifierNeuron</span><span class="o">&gt;</span><span class="w"> </span><span class="n">DenseLayer</span><span class="p">;</span>

<span class="c1">//build encoder network</span>
<span class="n">DenseLayer</span><span class="w"> </span><span class="nf">encoder1</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">hidden1</span><span class="p">);</span>
<span class="n">DenseLayer</span><span class="w"> </span><span class="nf">encoder2</span><span class="p">(</span><span class="n">encoder1</span><span class="p">.</span><span class="n">outputShape</span><span class="p">(),</span><span class="n">hidden2</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">encoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">encoder1</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">encoder2</span><span class="p">;</span>

<span class="c1">//build decoder network</span>
<span class="n">DenseLayer</span><span class="w"> </span><span class="nf">decoder1</span><span class="p">(</span><span class="n">encoder2</span><span class="p">.</span><span class="n">outputShape</span><span class="p">(),</span><span class="w"> </span><span class="n">encoder2</span><span class="p">.</span><span class="n">inputShape</span><span class="p">());</span>
<span class="n">DenseLayer</span><span class="w"> </span><span class="nf">decoder2</span><span class="p">(</span><span class="n">encoder1</span><span class="p">.</span><span class="n">outputShape</span><span class="p">(),</span><span class="w"> </span><span class="n">encoder1</span><span class="p">.</span><span class="n">inputShape</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">decoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">decoder1</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">decoder2</span><span class="p">;</span>

<span class="c1">//Setup autoencoder model</span>
<span class="k">auto</span><span class="w"> </span><span class="n">autoencoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">encoder</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">decoder</span><span class="p">;</span>
</pre></div>
</div>
<p>Note that for the deeper layers we use the shape of the output of the
previous layers (in this case just a 1-d shape with the number of neurons) to
specify the shape of the input of the next layer.</p>
<p>Next, we set up the objective function. This should by now be looking
quite familiar.  We set up an <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_error_function.html">ErrorFunction</a> with the model and
the squared loss. Here we enable minibatch training to speed up
the training progress.
We create the <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_labeled_data.html">LabeledData</a> object from the
input data by setting the labels to be the same as the inputs. Finally
we add  two-norm regularisation by creating an instance of the
<a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_two_norm_regularizer.html">TwoNormRegularizer</a> class:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">//create the objective function as a regression problem</span>
<span class="n">LabeledData</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="p">,</span><span class="n">RealVector</span><span class="o">&gt;</span><span class="w"> </span><span class="n">trainSet</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">inputs</span><span class="p">(),</span><span class="n">data</span><span class="p">.</span><span class="n">inputs</span><span class="p">());</span><span class="c1">//labels identical to inputs</span>
<span class="n">SquaredLoss</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="o">&gt;</span><span class="w"> </span><span class="n">loss</span><span class="p">;</span>
<span class="n">ErrorFunction</span><span class="o">&lt;&gt;</span><span class="w"> </span><span class="n">error</span><span class="p">(</span><span class="n">trainSet</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">autoencoder</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span><span class="c1">//we enable minibatch learning</span>
<span class="n">TwoNormRegularizer</span><span class="o">&lt;&gt;</span><span class="w"> </span><span class="n">regularizer</span><span class="p">(</span><span class="n">error</span><span class="p">.</span><span class="n">numberOfVariables</span><span class="p">());</span>
<span class="n">error</span><span class="p">.</span><span class="n">setRegularizer</span><span class="p">(</span><span class="n">regularisation</span><span class="p">,</span><span class="o">&amp;</span><span class="n">regularizer</span><span class="p">);</span>
<span class="n">initRandomNormal</span><span class="p">(</span><span class="n">autoencoder</span><span class="p">,</span><span class="mf">0.01</span><span class="p">);</span>
</pre></div>
</div>
<p>Lastly, we optimize the objective using <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_adam.html">Adam</a>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">Adam</span><span class="o">&lt;&gt;</span><span class="w"> </span><span class="n">optimizer</span><span class="p">;</span>
<span class="n">error</span><span class="p">.</span><span class="n">init</span><span class="p">();</span>
<span class="n">optimizer</span><span class="p">.</span><span class="n">init</span><span class="p">(</span><span class="n">error</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;Optimizing model &quot;</span><span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="k">for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">iterations</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">){</span>
<span class="w">        </span><span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">error</span><span class="p">);</span>
<span class="w">        </span><span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="w">  </span><span class="o">%</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="w">                </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="n">i</span><span class="o">&lt;&lt;</span><span class="s">&quot; &quot;</span><span class="o">&lt;&lt;</span><span class="n">optimizer</span><span class="p">.</span><span class="n">solution</span><span class="p">().</span><span class="n">value</span><span class="o">&lt;&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">autoencoder</span><span class="p">.</span><span class="n">setParameterVector</span><span class="p">(</span><span class="n">optimizer</span><span class="p">.</span><span class="n">solution</span><span class="p">().</span><span class="n">point</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="visualizing-the-autoencoder">
<h2>Visualizing the autoencoder<a class="headerlink" href="#visualizing-the-autoencoder" title="Link to this heading">¶</a></h2>
<p>After training the different architectures, we printed the feature maps of the first layer
(i.e., the input weights of the hidden neurons ordered according to the pixels they are connected to). Let’s have a look.</p>
<blockquote>
<div><p>exportFiltersToPGMGrid(“features”,encoder1.matrix(),28,28);</p>
</div></blockquote>
<figure class="align-default">
<img alt="Plot of features learned by the normal autoencoders" src="../../../_images/featuresAutoencoder.png" />
</figure>
</section>
<section id="what-next">
<h2>What next?<a class="headerlink" href="#what-next" title="Link to this heading">¶</a></h2>
<p>The next tutorials covers <a class="reference internal" href="variational_autoencoders.html"><span class="doc">Variational Autoencoders</span></a></p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
	<div class="mt_ltocwrapper">
		<ul>
<li><a class="reference internal" href="#">Autoencoders</a><ul>
<li><a class="reference internal" href="#training-autoencoders">Training autoencoders</a></li>
<li><a class="reference internal" href="#visualizing-the-autoencoder">Visualizing the autoencoder</a></li>
<li><a class="reference internal" href="#what-next">What next?</a></li>
</ul>
</li>
</ul>

	</div>
<div>
  <a class="topless" href="DeepMNIST.html" title="previous chapter">
	  <img class="navicon" src="../../../_static/icon_backward.png" alt="prev"/> Data Shapes and Deep Convolutional Architectures</a>
  <a class="topless" href="variational_autoencoders.html" title="next chapter">
	  <img class="navicon" src="../../../_static/icon_forward.png" alt="next"/> Variational Autoencoders</a>
</div> 
<div id="searchbox" style="display: none">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" size="12" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      <input class="mtsubmitbutton" type="submit" value="Find" />
    </form>
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
<p class="mtshowsource">
  <a href="../../../_sources/rest_sources/tutorials/algorithms/autoencoders.rst.txt"
           rel="nofollow"><img class="sourceicon" src="../../../_static/icon_eject.png" alt="prev"/> Show page source</a>
</p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
        <div class="footerlogos">
            <a href="http://validator.w3.org/check/referer" title="Valid XHTML 1.0">
                <img class="footerlogos" src="../../../_static/xhtml_validation.png" alt="Valid XHTML 1.0" />
            </a>
            <a href="http://jigsaw.w3.org/css-validator/check/referer?profile=css3" title="Valid CSS3">
                <img class="footerlogos" src="../../../_static/css_validation.png" alt="Valid CSS3" />
            </a>
        </div>
            &copy; The Shark developer team.
           Created on 21/05/2024
           using <a href="http://sphinx.pocoo.org/">Sphinx</a> 7.3.7
    </div>
  </body>
</html>