<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    
    <title>Support Vector Machines: Model Selection Using Cross-Validation and Grid-Search &#8212; Shark 3.0a documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mt_sphinx_deriv.css?v=6ec4729f" />
    <script src="../../../_static/documentation_options.js?v=db277b1a"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntilConfig"></script>
    <link rel="icon" href="../../../_static/shark16.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Support Vector Machines: Likelihood-based Model Selection" href="svmLikelihoodModelSelection.html" />
    <link rel="prev" title="Support Vector Machines: First Steps" href="svm.html" />
    <link rel="stylesheet" href="../../../_static/mt_sphinx_shark.css" type="text/css" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../index/../../../../mlstyle.js"></script>

  </head><body>

    <div id="shark_old">
        <div id="wrap">
            <div id="header">
                <div id="site-name"><a href="/shark/index.html">Shark machine learning library</a></div>
                <ul id="nav">
                    <li  class="first" >
                        <a href="../../installation.html">Installation</a>
                    </li>
                    <li  class="active" >
                        <a href="../tutorials.html">Tutorials</a>
                    </li>
		    <li  class="first" >
                        <a href="../../benchmark.html">Benchmarks</a>
                    </li>
		    <li  class="first" >
                        <a href="../../../index/../../../../doxygen_pages/html/classes.html">Documentation</a>
                        <ul>
                            <li><a href="../../quickref/quickref.html">Quick references</a></li>
                            <li><a href="../../../index/../../../../doxygen_pages/html/classes.html">Class list</a></li>
                            <li class="last"><a href="../../../index/../../../../doxygen_pages/html/group__shark__globals.html">Global functions</a></li>
                        </ul>
                    </li>
                </ul>

            </div>
        </div>
    </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="support-vector-machines-model-selection-using-cross-validation-and-grid-search">
<h1>Support Vector Machines: Model Selection Using Cross-Validation and Grid-Search<a class="headerlink" href="#support-vector-machines-model-selection-using-cross-validation-and-grid-search" title="Link to this heading">¶</a></h1>
<p>Please read the <a class="reference internal" href="svm.html"><span class="doc">Support Vector Machines: First Steps</span></a> tutorial first to follow the SVM example.
However, the part on cross-validation and grid-search works of course
also for other classifiers.</p>
<p>The performance of your SVM classifier depends on the choice of the
regularization parameter <span class="math notranslate nohighlight">\(C\)</span> and the kernel parameters.
For a standard radial Gaussian kernel</p>
<div class="math notranslate nohighlight">
\[k(x, z) = \exp(-\gamma \|x- z\|^2) = \exp( - \|x- z\|^2 / (2\sigma^2))\]</div>
<p>the bandwidth parameter <span class="math notranslate nohighlight">\(\gamma\)</span> (or <span class="math notranslate nohighlight">\(\sigma\)</span>) is the
only kernel parameter.  Adapting the “hyperparameters” is referred
to as SVM model selection.</p>
<p>The Shark library offers many algorithms for SVM model selection.
In this tutorial, we consider the most basic approach.</p>
<section id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Link to this heading">¶</a></h2>
<p>Cross-validation (CV) is a standard technique for adjusting
hyperparameters of predictive models.  In K-fold CV, the available
data <span class="math notranslate nohighlight">\(S\)</span> is partitioned into K subsets <span class="math notranslate nohighlight">\(S_1,\dots,
S_K\)</span>. Each data point in <span class="math notranslate nohighlight">\(S\)</span> is randomly assigned to one of the
subsets such that these are of almost equal size (i.e., <span class="math notranslate nohighlight">\(\lfloor
|S|/K\rfloor \leq |S_i|\leq \lceil |S|/K\rceil\)</span>).  Further, we define
<span class="math notranslate nohighlight">\(S_{\setminus i}=\bigcup_{j=1,\dots,K \wedge j\neq i} S_i\)</span> as
the union of all data points except those in <span class="math notranslate nohighlight">\(S_i\)</span>.  For each
<span class="math notranslate nohighlight">\(i=1,\dots,K\)</span>, an individual model is built by applying the
algorithm to the training data <span class="math notranslate nohighlight">\(S_{\setminus i}\)</span>. This model is
then evaluated by means of a cost function using the test data in
<span class="math notranslate nohighlight">\(S_i\)</span>. The average of the K outcomes of the model evaluations is
called <em>cross-validation (test) performance</em> or
<em>cross-validation (test) error</em> and is used a predictor of the
performance of the algorithm when applied to <span class="math notranslate nohighlight">\(S\)</span>.  Typical
values for K are 5 and 10 <a class="reference internal" href="#hastietibshiranifriedman-2008" id="id1"><span>[HastieTibshiraniFriedman-2008]</span></a>.</p>
<p>To choose <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(\gamma\)</span> using K-fold CV, we first split
the available data into K subsets.  Then we compute the CV error using
this split error for the SVM classifiers using different values for
<span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(\gamma\)</span>.  Finally, we pick the <span class="math notranslate nohighlight">\(C\)</span> and
<span class="math notranslate nohighlight">\(\gamma\)</span> with the lowest CV error and use it for training an SVM
on the complete data set <span class="math notranslate nohighlight">\(S\)</span>.</p>
</section>
<section id="jaakkola-s-heuristic">
<h2>Jaakkola’s heuristic<a class="headerlink" href="#jaakkola-s-heuristic" title="Link to this heading">¶</a></h2>
<p>Jaakkola’s heuristic <a class="reference internal" href="#jaakkoladiekhaushaussler1999" id="id2"><span>[JaakkolaDiekhausHaussler1999]</span></a> provides a reasonable initial guess for the
bandwidth parameter <span class="math notranslate nohighlight">\(\gamma\)</span> or <span class="math notranslate nohighlight">\(\sigma\)</span> of a Gaussian
kernel.</p>
<p>To estimate a good value for <span class="math notranslate nohighlight">\(\sigma\)</span>, consider all pairs
consisting of an training input vector from the positive class and a
training input vector from the negative class.  Compute the difference
in input space between all pairs.  The median of these distances can
be used as a measure of scale and therefore as a guess for <span class="math notranslate nohighlight">\(\sigma\)</span>.
More formally, compute</p>
<div class="math notranslate nohighlight">
\[G=\{  \|x_i - x_j\|\,|\, (x_i, y_i), (x_j,y_j)\in S \wedge y_i\neq y_j\}\]</div>
<p>based on your training data <span class="math notranslate nohighlight">\(S\)</span>.
Then set  <span class="math notranslate nohighlight">\(\sigma_{\text{Jaakkola}}\)</span> equal to the median of the values
in <span class="math notranslate nohighlight">\(G\)</span>:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\text{Jaakkola}} = \operatorname{median}(G)\]</div>
</section>
<section id="svm-model-selection-in-shark">
<h2>SVM Model Selection in Shark<a class="headerlink" href="#svm-model-selection-in-shark" title="Link to this heading">¶</a></h2>
<p>We consider the same toy problem and the same models as in the tutorial
<a class="reference internal" href="svm.html"><span class="doc">Support Vector Machines: First Steps</span></a>. We additionally include:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/ObjectiveFunctions/CrossValidationError.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Algorithms/DirectSearch/GridSearch.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shark/Algorithms/JaakkolaHeuristic.h&gt;</span>
</pre></div>
</div>
<p>for computing the cross-validation error, for calculating Jaakkola’s
Heuristic, and for optimizing the parameters using grid-search,
respectively.</p>
<section id="preparing-the-svm-for-unconstraint-optimization">
<h3>Preparing the SVM for unconstraint optimization<a class="headerlink" href="#preparing-the-svm-for-unconstraint-optimization" title="Link to this heading">¶</a></h3>
<p>Our model and trainer are now given by:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">GaussianRbfKernel</span><span class="o">&lt;&gt;</span><span class="w"> </span><span class="n">kernel</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span><span class="w"> </span><span class="c1">//unconstrained?</span>
<span class="n">KernelClassifier</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="o">&gt;</span><span class="w"> </span><span class="n">svm</span><span class="p">;</span>
<span class="kt">bool</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="kt">bool</span><span class="w"> </span><span class="n">unconstrained</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="n">CSvmTrainer</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="o">&gt;</span><span class="w"> </span><span class="n">trainer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="n">unconstrained</span><span class="p">);</span>
</pre></div>
</div>
<p>The Boolean flags set to true in the constructors of
<a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_gaussian_rbf_kernel.html">GaussianRbfKernel</a> and <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_c_svm_trainer.html">CSvmTrainer</a> indicate that the
kernel parameter <span class="math notranslate nohighlight">\(\gamma\)</span> and the regularization parameter
<span class="math notranslate nohighlight">\(C\)</span>, which “belongs” to the trainer, are <em>internally</em> encoded as
<span class="math notranslate nohighlight">\(\ln \gamma\)</span> and <span class="math notranslate nohighlight">\(\ln C\)</span>.  Because both parameters have to
be positive, this encoding allows for unconstraint optimization (e.g.,
if the model parameter encoding the kernel width is set to -1, we have
<span class="math notranslate nohighlight">\(\gamma =1/e\)</span>).  This encoding affects the interface between
model, objective function, and optimizer, but <em>not</em> functions such as
<code class="docutils literal notranslate"><span class="pre">setGamma</span></code>, <code class="docutils literal notranslate"><span class="pre">setSigma</span></code> or <code class="docutils literal notranslate"><span class="pre">setC</span></code>. These behave always the same
regardless of the internal encoding.</p>
</section>
<section id="id3">
<h3>Cross-validation<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<p>Now we define the
cross-validation error. First let us define the folds we need</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span><span class="w">  </span><span class="c1">// number of folds</span>
<span class="n">ZeroOneLoss</span><span class="o">&lt;</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">loss</span><span class="p">;</span>
<span class="n">CVFolds</span><span class="o">&lt;</span><span class="n">ClassificationDataset</span><span class="o">&gt;</span><span class="w"> </span><span class="n">folds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">createCVSameSizeBalanced</span><span class="p">(</span><span class="n">dataTrain</span><span class="p">,</span><span class="w"> </span><span class="n">K</span><span class="p">);</span>
</pre></div>
</div>
<p>The first line sets the number of folds <span class="math notranslate nohighlight">\(K\)</span> to 5. Then we define the
basic error measure underlying the cross-validation error, here the
standard 0-1 loss. Note that we do classification here, so we need
to use unsigned int as the template parameter for the 0-1 loss.
After that we split the available training data
into <span class="math notranslate nohighlight">\(K\)</span> folds using the function <a class="reference external" href="../../../../../../doxygen_pages/html/group__shark__globals.html#gabb5bec2fca9d1eaa2ea58c75d36d1195">createCVSameSizeBalanced()</a> from
<code class="docutils literal notranslate"><span class="pre">Data/CVDatasetTools.h</span></code>.</p>
<p>Then we need to instantiate <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_cross_validation_error.html">CrossValidationError</a>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">CrossValidationError</span><span class="o">&lt;</span><span class="n">KernelClassifier</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">cvError</span><span class="p">(</span>
<span class="w">        </span><span class="n">folds</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">trainer</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">svm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">trainer</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">loss</span>
<span class="p">);</span>
</pre></div>
</div>
<p>The template arguments of
<a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_cross_validation_error.html">CrossValidationError</a> specify the model and that the
given labels are unsigned integers (encoding classes).  The first parameter of the
constructor is just the data in form of the folds we defined.
The last parameter is the loss function on which the CV error
is based. But what about the
other three parameters?  The <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_cross_validation_error.html">CrossValidationError</a> works as follows.
A new parameter configuration is written into an “meta” object <em>A</em>
that is <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_i_parameterizable.html">IParameterizable</a> (such as a regularizer or a trainer, in
our case the trainer we defined earlier).
Then the specified model <em>B</em> is trained with the specified trainer
<em>C</em>.  The pointers to <em>A</em>, <em>B</em>, and <em>C</em> are the arguments 2, 3, and 4
of the constructor.  In our case of SVM model selection, the meta
object and the trainer are the same, this is why the trainer
occurs twice as a parameter.</p>
</section>
<section id="id4">
<h3>Jaakkola’s heuristic<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<p>To find a good starting point for <span class="math notranslate nohighlight">\(\gamma\)</span>, we apply Jaakkola’s heuristic</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">JaakkolaHeuristic</span><span class="w"> </span><span class="nf">ja</span><span class="p">(</span><span class="n">dataTrain</span><span class="p">);</span>
<span class="kt">double</span><span class="w"> </span><span class="n">ljg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">ja</span><span class="p">.</span><span class="n">gamma</span><span class="p">());</span>
</pre></div>
</div>
<p>as defined above.</p>
</section>
<section id="grid-search">
<h3>Grid-search<a class="headerlink" href="#grid-search" title="Link to this heading">¶</a></h3>
<p>We have two hyperparameters.
To adapt them using grid-search, we have to define a two-dimensional
grid. Let us consider 9 grid points for
<span class="math notranslate nohighlight">\(\ln \gamma\)</span> and 11 for <span class="math notranslate nohighlight">\(\ln C\)</span>.
Let</p>
<div class="math notranslate nohighlight">
\[\ln \gamma\in\{\ln\gamma_{\text{Jaakkola}}-4, \ln\gamma_{\text{Jaakkola}}-3,\dots,\ln\gamma_{\text{Jaakkola}},\dots,\ln\gamma_{\text{Jaakkola}}+4\}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\ln C\in\{0,1,\dots,10\} .\]</div>
<p>and define the grid accordingly:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">GridSearch</span><span class="w"> </span><span class="n">grid</span><span class="p">;</span>
<span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
<span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
<span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sections</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
<span class="c1">// kernel parameter gamma</span>
<span class="n">min</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ljg</span><span class="mf">-4.</span><span class="p">;</span><span class="w"> </span><span class="n">max</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ljg</span><span class="o">+</span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="n">sections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span><span class="p">;</span>
<span class="c1">// regularization parameter C</span>
<span class="n">min</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span><span class="w"> </span><span class="n">max</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">10.0</span><span class="p">;</span><span class="w"> </span><span class="n">sections</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">11</span><span class="p">;</span>
<span class="n">grid</span><span class="p">.</span><span class="n">configure</span><span class="p">(</span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">,</span><span class="w"> </span><span class="n">sections</span><span class="p">);</span>
</pre></div>
</div>
<p>The optimizer <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_grid_search.html">GridSearch</a> “sees” the parameter in the
logarithmic encoding we activated in the model and trainier definition
above. Therefore, we specify a linear grid while searching on
logarithmic scale. Now we do the grid search by</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">cvError</span><span class="p">);</span>
</pre></div>
</div>
<p>and finally train the model using all data and the best parameters</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="p">.</span><span class="n">setParameterVector</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="n">solution</span><span class="p">().</span><span class="n">point</span><span class="p">);</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span><span class="w"> </span><span class="n">dataTrain</span><span class="p">);</span>
</pre></div>
</div>
<p>and evaluate the model as described in <a class="reference internal" href="svm.html"><span class="doc">Support Vector Machines: First Steps</span></a>.</p>
</section>
</section>
<section id="full-example-program">
<h2>Full example program<a class="headerlink" href="#full-example-program" title="Link to this heading">¶</a></h2>
<p>The full example program for tutorial is <a class="reference external" href="../../../../../../doxygen_pages/html/_c_svm_grid_search_tutorial_8cpp.html">CSvmGridSearchTutorial.cpp</a>.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="hastietibshiranifriedman-2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">HastieTibshiraniFriedman-2008</a><span class="fn-bracket">]</span></span>
<p>T. Hastie, R. Tibshirani and
J. Friedman.  <a class="reference external" href="http://www-stat.stanford.edu/~tibs/ElemStatLearn">The Elements of Statistical Learning</a>, section 4.3. Springer-Verlag,
2008.</p>
</div>
<div class="citation" id="jaakkoladiekhaushaussler1999" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">JaakkolaDiekhausHaussler1999</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="20">
<li><p>Jaakkola, M. Diekhaus, and D. Haussler. Using the Fisher kernel method to detect remote protein homologies. In T. Lengauer, R. Schneider, P. Bork, D. Brutlad, J. Glasgow, H.- W. Mewes, and R. Zimmer, editors, Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology, pages 149-158. AAAI Press, 1999.</p></li>
</ol>
</div>
</div>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
	<div class="mt_ltocwrapper">
		<ul>
<li><a class="reference internal" href="#">Support Vector Machines: Model Selection Using Cross-Validation and Grid-Search</a><ul>
<li><a class="reference internal" href="#cross-validation">Cross-validation</a></li>
<li><a class="reference internal" href="#jaakkola-s-heuristic">Jaakkola’s heuristic</a></li>
<li><a class="reference internal" href="#svm-model-selection-in-shark">SVM Model Selection in Shark</a></li>
<li><a class="reference internal" href="#full-example-program">Full example program</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

	</div>
<div>
  <a class="topless" href="svm.html" title="previous chapter">
	  <img class="navicon" src="../../../_static/icon_backward.png" alt="prev"/> Support Vector Machines: First Steps</a>
  <a class="topless" href="svmLikelihoodModelSelection.html" title="next chapter">
	  <img class="navicon" src="../../../_static/icon_forward.png" alt="next"/> Support Vector Machines: Likelihood-based Model Selection</a>
</div> 
<div id="searchbox" style="display: none">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" size="12" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      <input class="mtsubmitbutton" type="submit" value="Find" />
    </form>
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
<p class="mtshowsource">
  <a href="../../../_sources/rest_sources/tutorials/algorithms/svmModelSelection.rst.txt"
           rel="nofollow"><img class="sourceicon" src="../../../_static/icon_eject.png" alt="prev"/> Show page source</a>
</p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
        <div class="footerlogos">
            <a href="http://validator.w3.org/check/referer" title="Valid XHTML 1.0">
                <img class="footerlogos" src="../../../_static/xhtml_validation.png" alt="Valid XHTML 1.0" />
            </a>
            <a href="http://jigsaw.w3.org/css-validator/check/referer?profile=css3" title="Valid CSS3">
                <img class="footerlogos" src="../../../_static/css_validation.png" alt="Valid CSS3" />
            </a>
        </div>
            &copy; The Shark developer team.
           Created on 21/05/2024
           using <a href="http://sphinx.pocoo.org/">Sphinx</a> 7.3.7
    </div>
  </body>
</html>